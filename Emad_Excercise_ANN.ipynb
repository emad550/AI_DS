{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emad_Excercise_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6udxFvRpjOJrKwtS5/8X2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emad550/AI_DS/blob/main/Emad_Excercise_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCezVrHvEd8U"
      },
      "source": [
        "#import liberaries \r\n",
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras import datasets\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "sns.set(rc={'figure.figsize': [9, 9]}, font_scale=1.2)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2cN9ua0O0H2"
      },
      "source": [
        "# load the dataset here\r\n",
        "(Xtrain, Ytrain), (Xtest, Ytest) = datasets.cifar10.load_data()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "bn5MZcP4PLAX",
        "outputId": "b0d14f85-f5ba-4460-ef4a-641b07b93ca2"
      },
      "source": [
        "# index a random batch of the images, targets array and plot it\r\n",
        "i = np.random.randint(0, 1000)\r\n",
        "\r\n",
        "plt.imshow(Xtrain[i], \"gray\")   \r\n",
        "# plt.grid(True)\r\n",
        "plt.title(Ytrain[i])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '[1]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRJbxOqyPYNP",
        "outputId": "9455b56f-4d2a-42d9-9fae-df5b33c6c765"
      },
      "source": [
        "N_train_imgs = Xtrain.shape[0]\r\n",
        "N_test_imgs = Xtest.shape[0]\r\n",
        "\r\n",
        "\r\n",
        "Xtrain = Xtrain.reshape(N_train_imgs, -1)\r\n",
        "Xtrain = Xtrain / 255. \r\n",
        "Ytrain = to_categorical(Ytrain)\r\n",
        "\r\n",
        "Xtest = Xtest.reshape(N_test_imgs, -1)\r\n",
        "Xtest = Xtest / 255. \r\n",
        "Ytest = to_categorical(Ytest)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Xtrain shape: \", Xtrain.shape, \"ytrain shape: \", Ytrain.shape)\r\n",
        "print(\"Xtest shape: \", Xtest.shape, \"Ytest shape: \", Ytest.shape)\r\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain shape:  (50000, 3072) ytrain shape:  (50000, 10)\n",
            "Xtest shape:  (10000, 3072) Ytest shape:  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5PEeiF1Pofk"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Dense(units=32, activation='relu', input_shape=[3072]),\r\n",
        "    #Dropout(0.2),\r\n",
        "    Dense(units=64, activation='relu'),\r\n",
        "    #Dropout(0.2),\r\n",
        "    #Dense(units=128, activation='relu'),\r\n",
        "    #Flatten(),\r\n",
        "\r\n",
        "    Dense(units=10, activation=\"softmax\")\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4bHh_ZKq0sI",
        "outputId": "f1f8f97a-af9d-415b-940e-aae5e0b1fdc5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 32)                98336     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 101,098\n",
            "Trainable params: 101,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeviGQ4rZRj"
      },
      "source": [
        "# configure the loss and optimizer and the metrics for the training\r\n",
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',\r\n",
        "                         patience = 10,\r\n",
        "                         verbose = 1,\r\n",
        "                         factor = 0.85,\r\n",
        "                         min_lr = 1e-6)\r\n",
        "\r\n",
        "mcp = ModelCheckpoint(\"./model\", verbose=1, save_best_only=True)\r\n",
        "\r\n",
        "es = EarlyStopping(verbose=1, patience=10)\r\n",
        "\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001),metrics=[\"acc\"] )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWuObqHnrxWX",
        "outputId": "ad0438c6-8b54-49a4-994d-276bedbc0d01"
      },
      "source": [
        "# feed the data and train the network\r\n",
        "history = model.fit(Xtrain, Ytrain, validation_split=0.25, batch_size=32, epochs=50,callbacks=[lrd, mcp, es])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 2.0449 - acc: 0.2305 - val_loss: 1.8607 - val_acc: 0.3174\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.86068, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 2/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.8556 - acc: 0.3153 - val_loss: 1.8414 - val_acc: 0.3274\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.86068 to 1.84136, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 3/50\n",
            "1172/1172 [==============================] - 4s 4ms/step - loss: 1.8351 - acc: 0.3280 - val_loss: 1.8431 - val_acc: 0.3279\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.84136\n",
            "Epoch 4/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.8154 - acc: 0.3389 - val_loss: 1.8278 - val_acc: 0.3323\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.84136 to 1.82785, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 5/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.8171 - acc: 0.3391 - val_loss: 1.8116 - val_acc: 0.3399\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.82785 to 1.81161, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 6/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.7903 - acc: 0.3480 - val_loss: 1.7933 - val_acc: 0.3479\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.81161 to 1.79331, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 7/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.7832 - acc: 0.3469 - val_loss: 1.8145 - val_acc: 0.3438\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.79331\n",
            "Epoch 8/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.7739 - acc: 0.3540 - val_loss: 1.7939 - val_acc: 0.3521\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.79331\n",
            "Epoch 9/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.7531 - acc: 0.3646 - val_loss: 1.7828 - val_acc: 0.3590\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.79331 to 1.78278, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 10/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.7467 - acc: 0.3662 - val_loss: 1.7768 - val_acc: 0.3537\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.78278 to 1.77678, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 11/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.7382 - acc: 0.3678 - val_loss: 1.7636 - val_acc: 0.3670\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.77678 to 1.76365, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 12/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.7279 - acc: 0.3775 - val_loss: 1.8072 - val_acc: 0.3493\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.76365\n",
            "Epoch 13/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.7342 - acc: 0.3727 - val_loss: 1.7514 - val_acc: 0.3654\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.76365 to 1.75144, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 14/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.7230 - acc: 0.3765 - val_loss: 1.7400 - val_acc: 0.3675\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.75144 to 1.74003, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 15/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.7118 - acc: 0.3798 - val_loss: 1.7549 - val_acc: 0.3633\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.74003\n",
            "Epoch 16/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.7051 - acc: 0.3835 - val_loss: 1.7553 - val_acc: 0.3613\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.74003\n",
            "Epoch 17/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.7001 - acc: 0.3863 - val_loss: 1.7348 - val_acc: 0.3741\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.74003 to 1.73481, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 18/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6907 - acc: 0.3887 - val_loss: 1.7389 - val_acc: 0.3689\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.73481\n",
            "Epoch 19/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6892 - acc: 0.3961 - val_loss: 1.7150 - val_acc: 0.3813\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.73481 to 1.71499, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 20/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6809 - acc: 0.3929 - val_loss: 1.7254 - val_acc: 0.3768\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.71499\n",
            "Epoch 21/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6763 - acc: 0.3901 - val_loss: 1.7367 - val_acc: 0.3642\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.71499\n",
            "Epoch 22/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6829 - acc: 0.3947 - val_loss: 1.7285 - val_acc: 0.3707\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.71499\n",
            "Epoch 23/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.6750 - acc: 0.3934 - val_loss: 1.7625 - val_acc: 0.3605\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.71499\n",
            "Epoch 24/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6695 - acc: 0.3935 - val_loss: 1.7150 - val_acc: 0.3779\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.71499 to 1.71497, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 25/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6668 - acc: 0.3951 - val_loss: 1.7157 - val_acc: 0.3763\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.71497\n",
            "Epoch 26/50\n",
            "1172/1172 [==============================] - 3s 3ms/step - loss: 1.6629 - acc: 0.3957 - val_loss: 1.7165 - val_acc: 0.3757\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.71497\n",
            "Epoch 27/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6600 - acc: 0.3989 - val_loss: 1.7305 - val_acc: 0.3731\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.71497\n",
            "Epoch 28/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6653 - acc: 0.3965 - val_loss: 1.7426 - val_acc: 0.3660\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.71497\n",
            "Epoch 29/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6694 - acc: 0.3933 - val_loss: 1.7420 - val_acc: 0.3742\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0008500000403728336.\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.71497\n",
            "Epoch 30/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6543 - acc: 0.4003 - val_loss: 1.7072 - val_acc: 0.3778\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.71497 to 1.70719, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 31/50\n",
            "1172/1172 [==============================] - 4s 4ms/step - loss: 1.6427 - acc: 0.4087 - val_loss: 1.7100 - val_acc: 0.3806\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.70719\n",
            "Epoch 32/50\n",
            "1172/1172 [==============================] - 4s 4ms/step - loss: 1.6502 - acc: 0.4016 - val_loss: 1.7061 - val_acc: 0.3788\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.70719 to 1.70612, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 33/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6452 - acc: 0.4023 - val_loss: 1.7320 - val_acc: 0.3760\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.70612\n",
            "Epoch 34/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6509 - acc: 0.4009 - val_loss: 1.7399 - val_acc: 0.3753\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.70612\n",
            "Epoch 35/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6446 - acc: 0.4018 - val_loss: 1.7131 - val_acc: 0.3779\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.70612\n",
            "Epoch 36/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6395 - acc: 0.4043 - val_loss: 1.7093 - val_acc: 0.3786\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.70612\n",
            "Epoch 37/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6503 - acc: 0.4010 - val_loss: 1.7210 - val_acc: 0.3730\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.70612\n",
            "Epoch 38/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6341 - acc: 0.4094 - val_loss: 1.7048 - val_acc: 0.3818\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.70612 to 1.70479, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 39/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6492 - acc: 0.4017 - val_loss: 1.7006 - val_acc: 0.3802\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.70479 to 1.70057, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 40/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6355 - acc: 0.4068 - val_loss: 1.7280 - val_acc: 0.3704\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.70057\n",
            "Epoch 41/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6312 - acc: 0.4104 - val_loss: 1.7111 - val_acc: 0.3802\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.70057\n",
            "Epoch 42/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6320 - acc: 0.4094 - val_loss: 1.7297 - val_acc: 0.3718\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.70057\n",
            "Epoch 43/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6378 - acc: 0.4092 - val_loss: 1.6952 - val_acc: 0.3810\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.70057 to 1.69515, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 44/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6339 - acc: 0.4117 - val_loss: 1.7021 - val_acc: 0.3822\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.69515\n",
            "Epoch 45/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6249 - acc: 0.4104 - val_loss: 1.7076 - val_acc: 0.3824\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.69515\n",
            "Epoch 46/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6336 - acc: 0.4103 - val_loss: 1.7166 - val_acc: 0.3754\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.69515\n",
            "Epoch 47/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6352 - acc: 0.4074 - val_loss: 1.7169 - val_acc: 0.3821\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.69515\n",
            "Epoch 48/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6332 - acc: 0.4076 - val_loss: 1.6999 - val_acc: 0.3854\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.69515\n",
            "Epoch 49/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6360 - acc: 0.4084 - val_loss: 1.6900 - val_acc: 0.3854\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.69515 to 1.69002, saving model to ./model\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Epoch 50/50\n",
            "1172/1172 [==============================] - 4s 3ms/step - loss: 1.6203 - acc: 0.4182 - val_loss: 1.7135 - val_acc: 0.3811\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.69002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "YXrHyGJnsqkD",
        "outputId": "8abb898b-ceb7-460c-8321-94b1fac487dc"
      },
      "source": [
        "# plot the loss history [train_loss, validation_loss] in a plot\r\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\r\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\r\n",
        "plt.legend()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d013857c4597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the loss history [train_loss, validation_loss] in a plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP6WrDoIRc0e"
      },
      "source": [
        "#we can use keras tuner but me be will do it later \r\n",
        "\r\n",
        "'''def build_model(hp):\r\n",
        "    model = keras.Sequential()\r\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\r\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\r\n",
        "                                            min_value=32,\r\n",
        "                                            max_value=512,\r\n",
        "                                            step=32),\r\n",
        "                               activation='relu'))\r\n",
        "    model.add(layers.Dense(1, activation='linear'))\r\n",
        "    model.compile(\r\n",
        "        optimizer=keras.optimizers.Adam(\r\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\r\n",
        "        loss='mean_absolute_error',\r\n",
        "        metrics=['mean_absolute_error'])\r\n",
        "    return model'''\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}